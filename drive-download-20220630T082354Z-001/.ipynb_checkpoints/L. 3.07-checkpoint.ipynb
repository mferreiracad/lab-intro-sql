{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "r97zMfY1myrW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "# prep: import modules and get pwd\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import getpass  # To get the password without showing the input\n",
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zvASXwGtmyrd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>operation</th>\n",
       "      <th>t_amount</th>\n",
       "      <th>balance</th>\n",
       "      <th>k_symbol</th>\n",
       "      <th>l_amount</th>\n",
       "      <th>duration</th>\n",
       "      <th>payments</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRIJEM</td>\n",
       "      <td>VKLAD</td>\n",
       "      <td>700.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRIJEM</td>\n",
       "      <td>VKLAD</td>\n",
       "      <td>900.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRIJEM</td>\n",
       "      <td>VKLAD</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRIJEM</td>\n",
       "      <td>VKLAD</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRIJEM</td>\n",
       "      <td>VKLAD</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     type operation  t_amount  balance k_symbol  l_amount  duration  payments  \\\n",
       "0  PRIJEM     VKLAD     700.0    700.0                NaN       NaN       NaN   \n",
       "1  PRIJEM     VKLAD     900.0    900.0                NaN       NaN       NaN   \n",
       "2  PRIJEM     VKLAD    1000.0   1000.0                NaN       NaN       NaN   \n",
       "3  PRIJEM     VKLAD     600.0    600.0                NaN       NaN       NaN   \n",
       "4  PRIJEM     VKLAD     400.0    400.0                NaN       NaN       NaN   \n",
       "\n",
       "  status  \n",
       "0   None  \n",
       "1   None  \n",
       "2   None  \n",
       "3   None  \n",
       "4   None  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data\n",
    "connection_string = 'mysql+pymysql://root:' + password + '@localhost/bank'\n",
    "engine = create_engine(connection_string)\n",
    "query = '''select t.type, t.operation, t.amount as t_amount, t.balance, t.k_symbol, l.amount as l_amount, l.duration, l.payments, l.status\n",
    "from trans t\n",
    "left join loan l\n",
    "on t.account_id = l.account_id;'''\n",
    "\n",
    "data = pd.read_sql_query(query, engine)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pBKmkFbmyre"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgLik82qmyrf"
   },
   "outputs": [],
   "source": [
    "# Activity 1\n",
    "#  pd.read_sql_table will accept a table name and will retrieve the whole table. \n",
    "#  You can also read a whole table with pd.read_sql. Try it on the table 'district'.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rn9906pcmyrf"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8F8oOS9myrf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# End Activity 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Hpcxl_7myrf"
   },
   "outputs": [],
   "source": [
    "data['status'].value_counts(dropna=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TDBRctWmyrg"
   },
   "outputs": [],
   "source": [
    "data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KkC4ie7Zmyrg"
   },
   "outputs": [],
   "source": [
    "data.dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYGheK8wmyrg"
   },
   "outputs": [],
   "source": [
    "data.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PlKRZXiJmyrh"
   },
   "outputs": [],
   "source": [
    "data = data[data['duration'].isna() == False]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Qk7Bce5myrh"
   },
   "outputs": [],
   "source": [
    "data.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lK-pzuKHmyrh"
   },
   "outputs": [],
   "source": [
    "data['duration'] = data['duration'].astype('object') # This will be treated as categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wcgwWpu-_woy"
   },
   "outputs": [],
   "source": [
    "data['duration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4pPtmt0myrh"
   },
   "outputs": [],
   "source": [
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HWG9wVnSmyri"
   },
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GW0xT2k-myri"
   },
   "outputs": [],
   "source": [
    "data['operation'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzTEarU1myri"
   },
   "outputs": [],
   "source": [
    "def cleanOperation(x):\n",
    "    x = x.lower()\n",
    "    if 'vyber' in x:\n",
    "        return \"vyber\"\n",
    "    elif 'prevod' in x:\n",
    "        return \"prevod\"\n",
    "    elif 'vklad' in x:\n",
    "        return 'vklad'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "data['operation'] = list(map(cleanOperation, data['operation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFrUd8Qomyri"
   },
   "outputs": [],
   "source": [
    "data['operation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stVSuVQRmyrj"
   },
   "outputs": [],
   "source": [
    "data['k_symbol'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "820iye85myrj"
   },
   "outputs": [],
   "source": [
    "data['k_symbol'].value_counts().index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEqES2o3myrj"
   },
   "outputs": [],
   "source": [
    "def cleankSymbol(x):\n",
    "    if x in ['', ' ']:\n",
    "        return 'unknown'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "data['k_symbol'] = list(map(cleankSymbol, data['k_symbol']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_6MaquMmyrj"
   },
   "outputs": [],
   "source": [
    "data['k_symbol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AgQ-rOkJmyrj"
   },
   "outputs": [],
   "source": [
    "data = data[~data['k_symbol'].isin(['POJISTNE', 'SANKC. UROK', 'UVER'])] # ~ : NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQiswBRS_wo2"
   },
   "outputs": [],
   "source": [
    "data['k_symbol'].isin(['POJISTNE', 'SANKC. UROK', 'UVER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZf7s7GAmyrk"
   },
   "outputs": [],
   "source": [
    "# discuss disadvantages and alternatives to dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cANrMGI3myrk"
   },
   "outputs": [],
   "source": [
    "data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V77dAiicmyrk"
   },
   "outputs": [],
   "source": [
    "# Activity 2:\n",
    "# Explore values in columns TYPE and OPERATION. \n",
    "# How many different loans of each type and operation are there? \n",
    "# How many loans for each combination? \n",
    "# (You may want to check out pandas.crosstab function.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c747Nstxmyrk"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoUzV98wmyrk"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.countplot(x=data.type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s59mwC8Gmyrk"
   },
   "outputs": [],
   "source": [
    "data.operation.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBBW7lhrmyrl"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=data.operation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62M1nuY6myrl"
   },
   "outputs": [],
   "source": [
    "pd.crosstab(data.type, data.operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMnSwY1Hmyrl"
   },
   "outputs": [],
   "source": [
    "#End Activity 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8HlGeRnfmyrl"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4chcGB59myrl"
   },
   "outputs": [],
   "source": [
    "# look for multicolinearity (some columns having almost identical correlation to other variables)\n",
    "# why can't we look for correlation with our target variable (status)?\n",
    "corr_matrix=data.corr(method='pearson')  # default\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax = sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "twruFD1rmyrl"
   },
   "outputs": [],
   "source": [
    "# look at the scale and distribution of values\n",
    "sns.displot(data['t_amount'])\n",
    "plt.show()\n",
    "\n",
    "sns.displot(data['l_amount'])\n",
    "plt.show()\n",
    "\n",
    "sns.displot(data['balance'])\n",
    "plt.show()\n",
    "\n",
    "sns.displot(data['payments'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9KUOmU4Kmyrm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_num = data.select_dtypes(include = np.number)\n",
    "X_cat = data.select_dtypes(include = np.object)\n",
    "\n",
    "# Scaling data\n",
    "transformer = MinMaxScaler().fit(X_num)\n",
    "x_normalized = transformer.transform(X_num)\n",
    "x_norm = pd.DataFrame(x_normalized)\n",
    "x_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdsBZN1D_wo6"
   },
   "outputs": [],
   "source": [
    "# Whoa, One step back please. What did I do wrong here?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZKrpQXJI_wo6"
   },
   "outputs": [],
   "source": [
    "# Need to X-y-split AND train-test-split BEFORE I apply transformations, \n",
    "# then train transformation on training set only\n",
    "y = data['status']\n",
    "X = data.drop('status', axis=1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j83qrxAG_wo6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_num = X_train.select_dtypes(include = np.number)\n",
    "\n",
    "# Scaling data\n",
    "transformer = MinMaxScaler().fit(X_train_num) # need to keep transformer\n",
    "X_train_normalized = transformer.transform(X_train_num)\n",
    "X_train_norm = pd.DataFrame(X_train_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CL6F5Lxh_wo7"
   },
   "outputs": [],
   "source": [
    "X_train_norm.columns = X_train_num.columns\n",
    "X_train_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3zKkBWymyrm"
   },
   "outputs": [],
   "source": [
    "X_train_categorical = X_train.select_dtypes(include = np.object)\n",
    "X_train_cat = pd.get_dummies(X_train_categorical, \n",
    "                             columns=['type', 'operation', 'k_symbol', 'duration'],\n",
    "                             drop_first=True)\n",
    "X_train_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZAv0_WvJmyrm"
   },
   "outputs": [],
   "source": [
    "# Activity 3\n",
    "# Explore visually the transformed numerical columns. What do you see?\n",
    "# Another typical transformation for numerical columns is to take the logarithm. \n",
    "# Apply the log transform to columns balance and t_ammount and compare the results with the scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMR9c6-Omyrm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mx1BEfS3myrn"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s17sSbjumyrn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-HgdiaPmyrn"
   },
   "outputs": [],
   "source": [
    "# End Activity 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0htv5PKmyrn"
   },
   "outputs": [],
   "source": [
    "# build X_train and y_train\n",
    "# remember: y = data['status'], y_train selected in train_test_split\n",
    "X_train_transformed = np.concatenate([X_train_norm, X_train_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYVSxoXimyrn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1E8DiZc8myro"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classification = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                  multi_class='multinomial').fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eyAugyQomyro"
   },
   "outputs": [],
   "source": [
    "classification = LogisticRegression(random_state=0, solver='saga',\n",
    "                  multi_class='multinomial').fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4p-ypzaBmyro"
   },
   "outputs": [],
   "source": [
    "# Can we now make predictions on the X_test?\n",
    "# predictions = classification.predict(X_test)\n",
    "# classification.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# NO - need to perform transformations on the X_test as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7lYNUxe_wo_"
   },
   "outputs": [],
   "source": [
    "# for numericals\n",
    "X_test_num = X_test.select_dtypes(include = np.number)\n",
    "\n",
    "# Scaling data\n",
    "# we use the transformer that was trained on the training data\n",
    "X_test_normalized = transformer.transform(X_test_num)\n",
    "X_test_norm = pd.DataFrame(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcnnAyXa_wo_"
   },
   "outputs": [],
   "source": [
    "# for categoricals\n",
    "X_test_categorical = X_test.select_dtypes(include = np.object)\n",
    "X_test_cat = pd.get_dummies(X_test_categorical, \n",
    "                            columns=['type', 'operation', 'k_symbol', 'duration'],\n",
    "                            drop_first=True)\n",
    "# verify that dummies columns are in the same order and that the same column was dropped\n",
    "display(list(zip(list(X_train_cat.columns),list(X_test_cat.columns))))\n",
    "# not needed if you treat each dataframe with one_hot_encoder and save the encode (and the column names)\n",
    "\n",
    "X_test_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zUMDEmnK_wpA"
   },
   "outputs": [],
   "source": [
    "X_test_transformed = np.concatenate([X_test_norm, X_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKsyJKmL_wpA"
   },
   "outputs": [],
   "source": [
    "# Now we can make predictions on the test set:\n",
    "predictions = classification.predict(X_test_transformed)\n",
    "classification.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKXKIjcPmyro"
   },
   "outputs": [],
   "source": [
    "print(y_test.value_counts())\n",
    "# As you would notice here, there is a huge imbalance in the data among the different classes. \n",
    "# We will talk more about imbalance and how to resolve it later (tomorrow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fuNSGscmyro"
   },
   "outputs": [],
   "source": [
    "pd.Series(predictions).value_counts()\n",
    "# This shows that the disparity in the numbers are amplified by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YhhzlfOmyrp"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwAsF1akmyrp"
   },
   "outputs": [],
   "source": [
    "# predicted | A | B | C | D |\n",
    "# --------------------------\n",
    "# actual  A | + |  |   |   |\n",
    "# --------------------------\n",
    "#         B |   | + |   |   |\n",
    "# --------------------------\n",
    "#         C |   |   | + |   |\n",
    "# --------------------------\n",
    "#         D |   |   |   | + |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "salXbiJgmyrp"
   },
   "outputs": [],
   "source": [
    "# bonus: KNN classifier: look at nearest neighbours and use the majority to determine class\n",
    "from sklearn import neighbors\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "clf.fit(X_train_transformed, y_train)\n",
    "predictions_clf = clf.predict(X_test_transformed)\n",
    "clf.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_mftgwJmyrp"
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3W0t-HHGmyrp"
   },
   "outputs": [],
   "source": [
    "pd.Series(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzHpesNAmyrp"
   },
   "outputs": [],
   "source": [
    "pd.Series(predictions_clf).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZeAzI8fmyrq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "L. 3.07.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
